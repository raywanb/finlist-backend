# Use Python 3.11 slim image for smaller size
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies including curl for health checks
RUN apt-get update && apt-get install -y \
    gcc \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Install GPT Researcher
RUN pip install --no-cache-dir gpt-researcher

# Copy application code
COPY crawler.py .
COPY database.py .

# Create non-root user for security
RUN useradd --create-home --shell /bin/bash app && chown -R app:app /app
USER app

# Create logs directory
RUN mkdir -p /app/logs

# Health check - check if crawler process is running
HEALTHCHECK --interval=60s --timeout=30s --start-period=30s --retries=3 \
    CMD ps aux | grep "crawler.py" | grep -v grep || exit 1

# Run the crawler in continuous mode with all sectors (24-hour interval)
CMD ["python", "crawler.py", "--interval", "86400", "--all-sectors"] 